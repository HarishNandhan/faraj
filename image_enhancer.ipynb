{
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "interpreter": {
      "hash": "46b7c30b1711f881edec1cefb47fa8e7b806a27d8400f86993747e043b220d88"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# __Importing required libraries__"
      ],
      "metadata": {
        "id": "vnp5XXJxzsQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import applications, Model, losses, layers, optimizers\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Nma-bzXn05Fd",
        "execution": {
          "iopub.status.busy": "2023-03-20T17:38:04.208787Z",
          "iopub.execute_input": "2023-03-20T17:38:04.209212Z",
          "iopub.status.idle": "2023-03-20T17:38:06.444860Z",
          "shell.execute_reply.started": "2023-03-20T17:38:04.209130Z",
          "shell.execute_reply": "2023-03-20T17:38:06.443876Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# __Config values__"
      ],
      "metadata": {
        "id": "akP-5GqMzw1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [========= Data Preprocessing =========]\n",
        "HR_SIZE = 128\n",
        "SCALE = 4\n",
        "LR_SIZE = int(HR_SIZE / 4)\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "GEN_FILTERS = 64\n",
        "DISC_FILTERS = 64"
      ],
      "metadata": {
        "id": "_AJAt3Hq5rJb",
        "execution": {
          "iopub.status.busy": "2023-03-20T17:38:06.447111Z",
          "iopub.execute_input": "2023-03-20T17:38:06.447789Z",
          "iopub.status.idle": "2023-03-20T17:38:06.454245Z",
          "shell.execute_reply.started": "2023-03-20T17:38:06.447748Z",
          "shell.execute_reply": "2023-03-20T17:38:06.451749Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# __Data preprocessing and augmentation__"
      ],
      "metadata": {
        "id": "Xeg6GnXkzzkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [====================================================]\n",
        "# [================ Random Compressions ===============]\n",
        "# [====================================================]\n",
        "\n",
        "def random_compression(example):\n",
        "    hr = example['hr']\n",
        "    hr_shape = tf.shape(hr)\n",
        "    compression_idx = tf.random.uniform(shape = (), maxval = 7, dtype = tf.int32)\n",
        "    \n",
        "    if compression_idx == 0 or compression_idx == 1:\n",
        "        # bicubic\n",
        "        lr = tf.image.resize(hr, [int(hr_shape[0] / SCALE), int(hr_shape[1] / SCALE)], method = 'bicubic')\n",
        "        lr = tf.cast(tf.round(tf.clip_by_value(lr, 0, 255)), tf.uint8)\n",
        "    elif compression_idx == 2 or compression_idx == 3:\n",
        "        # bilinear\n",
        "        lr = tf.image.resize(hr, [int(hr_shape[0] / SCALE), int(hr_shape[1] / SCALE)], method = 'bilinear')\n",
        "        lr = tf.cast(tf.round(tf.clip_by_value(lr, 0, 255)), tf.uint8)\n",
        "    elif compression_idx == 4 or compression_idx == 5:\n",
        "        # nearest\n",
        "        lr = tf.image.resize(hr, [int(hr_shape[0] / SCALE), int(hr_shape[1] / SCALE)], method = 'nearest')\n",
        "        lr = tf.cast(tf.round(tf.clip_by_value(lr, 0, 255)), tf.uint8)\n",
        "    else:\n",
        "        # default\n",
        "        lr = example['lr']\n",
        "    \n",
        "    return lr, hr\n",
        "\n",
        "# [======================================================]\n",
        "# [============= Spatial Random Augmentations ===========]\n",
        "# [======================================================]\n",
        "\n",
        "@tf.function()\n",
        "def random_crop(lr, hr):\n",
        "    lr_shape = tf.shape(lr)[:2]\n",
        "\n",
        "    lr_w = tf.random.uniform(shape = (), maxval = lr_shape[1] - LR_SIZE + 1, dtype = tf.int32)\n",
        "    lr_h = tf.random.uniform(shape = (), maxval = lr_shape[0] - LR_SIZE + 1, dtype = tf.int32)\n",
        "\n",
        "    hr_w = lr_w * int(SCALE)\n",
        "    hr_h = lr_h * int(SCALE)\n",
        "\n",
        "    lr_cropped = lr[lr_h:lr_h + LR_SIZE, lr_w: lr_w + LR_SIZE]\n",
        "    hr_cropped = hr[hr_h:hr_h + HR_SIZE, hr_w: hr_w + HR_SIZE]\n",
        "\n",
        "    return lr_cropped, hr_cropped\n",
        "\n",
        "@tf.function()\n",
        "def random_rotate(lr, hr):\n",
        "    rn = tf.random.uniform(shape = (), maxval = 4, dtype = tf.int32)\n",
        "    return tf.image.rot90(lr, rn), tf.image.rot90(hr, rn)\n",
        "\n",
        "@tf.function()\n",
        "def random_spatial_augmentation(lrs, hrs):\n",
        "    lrs, hrs = tf.cond(\n",
        "        tf.random.uniform(shape = (), maxval = 1) < 0.5,\n",
        "        lambda: (lrs, hrs),\n",
        "        lambda: random_rotate(lrs, hrs)\n",
        "    )\n",
        "\n",
        "    return tf.cast(lrs, tf.float32), tf.cast(hrs, tf.float32)"
      ],
      "metadata": {
        "id": "HXnva1AK76U1",
        "execution": {
          "iopub.status.busy": "2023-03-20T17:38:06.455944Z",
          "iopub.execute_input": "2023-03-20T17:38:06.456422Z",
          "iopub.status.idle": "2023-03-20T17:38:06.474298Z",
          "shell.execute_reply.started": "2023-03-20T17:38:06.456387Z",
          "shell.execute_reply": "2023-03-20T17:38:06.473373Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# __Downloading dataset and creating data loader__"
      ],
      "metadata": {
        "id": "34JtXn0k9YTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = tfds.load(f'div2k/bicubic_x{SCALE}', split = 'train', shuffle_files = True)\n",
        "train_data = train_data.map(random_compression, num_parallel_calls = tf.data.AUTOTUNE)\n",
        "train_data = train_data.map(random_crop, num_parallel_calls = tf.data.AUTOTUNE)\n",
        "train_data = train_data.batch(BATCH_SIZE, drop_remainder = True)\n",
        "train_data = train_data.map(random_spatial_augmentation, num_parallel_calls = tf.data.AUTOTUNE)\n",
        "\n",
        "train_data = train_data.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "5Zj_COZA-eVp",
        "execution": {
          "iopub.status.busy": "2023-03-20T17:38:06.476092Z",
          "iopub.execute_input": "2023-03-20T17:38:06.476333Z",
          "iopub.status.idle": "2023-03-20T17:44:27.724226Z",
          "shell.execute_reply.started": "2023-03-20T17:38:06.476310Z",
          "shell.execute_reply": "2023-03-20T17:44:27.723273Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/braindotai/Real-Time-Super-Resolution.git"
      ],
      "metadata": {
        "id": "wa9U4_kS6ERs",
        "execution": {
          "iopub.status.busy": "2023-03-20T17:44:27.727338Z",
          "iopub.execute_input": "2023-03-20T17:44:27.727764Z",
          "iopub.status.idle": "2023-03-20T17:44:34.126493Z",
          "shell.execute_reply.started": "2023-03-20T17:44:27.727728Z",
          "shell.execute_reply": "2023-03-20T17:44:34.125306Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for lrs, hrs in train_data:\n",
        "    break\n",
        "\n",
        "print(lrs.shape, hrs.shape)\n",
        "print(lrs.dtype, hrs.dtype)\n",
        "print(tf.reduce_min(lrs), tf.reduce_max(lrs))\n",
        "print(tf.reduce_min(hrs), tf.reduce_max(hrs))"
      ],
      "metadata": {
        "id": "rRuVUHjW-eNs",
        "execution": {
          "iopub.status.busy": "2023-03-20T17:44:34.128917Z",
          "iopub.execute_input": "2023-03-20T17:44:34.129332Z",
          "iopub.status.idle": "2023-03-20T17:44:39.382492Z",
          "shell.execute_reply.started": "2023-03-20T17:44:34.129287Z",
          "shell.execute_reply": "2023-03-20T17:44:39.381273Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5r0DesZr54lY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_samples(images_lists, titles = None, size = (12, 12), masked = False):\n",
        "    assert len(images_lists) == len(titles)\n",
        "    \n",
        "    cols = len(images_lists)\n",
        "    \n",
        "    for images in zip(*images_lists):\n",
        "        plt.figure(figsize = size)\n",
        "        for idx, image in enumerate(images):\n",
        "            plt.subplot(1, cols, idx + 1)\n",
        "            plt.imshow(tf.cast(tf.round(tf.clip_by_value(image, 0, 255)), tf.uint8))\n",
        "            plt.axis('off')\n",
        "            if titles:\n",
        "                plt.title(titles[idx])\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "BLoaZI43_fUV",
        "execution": {
          "iopub.status.busy": "2023-03-20T17:44:39.384209Z",
          "iopub.execute_input": "2023-03-20T17:44:39.384589Z",
          "iopub.status.idle": "2023-03-20T17:44:39.392665Z",
          "shell.execute_reply.started": "2023-03-20T17:44:39.384552Z",
          "shell.execute_reply": "2023-03-20T17:44:39.391432Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_samples(images_lists = (lrs[:15], hrs[:15]), titles = ('Low Resolution', 'High Resolution'), size = (8, 8))"
      ],
      "metadata": {
        "id": "LAguB0aNDldY",
        "execution": {
          "iopub.status.busy": "2023-03-20T17:44:39.394132Z",
          "iopub.execute_input": "2023-03-20T17:44:39.396778Z",
          "iopub.status.idle": "2023-03-20T17:44:41.485482Z",
          "shell.execute_reply.started": "2023-03-20T17:44:39.396741Z",
          "shell.execute_reply": "2023-03-20T17:44:41.484370Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# __Layers for creating models__"
      ],
      "metadata": {
        "id": "eH_lsIbMGjdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv2D(layers.Conv2D):\n",
        "    def __init__(self, kernel_size = 3, padding = 'same', **kwargs):\n",
        "        super(Conv2D, self).__init__(\n",
        "            kernel_size = kernel_size,\n",
        "            padding = padding,\n",
        "            bias_initializer = tf.keras.initializers.Zeros(),\n",
        "            **kwargs\n",
        "        )"
      ],
      "metadata": {
        "id": "P70CeqnJ9-JD",
        "execution": {
          "iopub.status.busy": "2023-03-20T17:44:41.487025Z",
          "iopub.execute_input": "2023-03-20T17:44:41.487397Z",
          "iopub.status.idle": "2023-03-20T17:44:41.493406Z",
          "shell.execute_reply.started": "2023-03-20T17:44:41.487341Z",
          "shell.execute_reply": "2023-03-20T17:44:41.492150Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# __Modules for creating models__"
      ],
      "metadata": {
        "id": "7ZXMEP9vTKOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv2DBlock(layers.Layer):\n",
        "    def __init__(self, filters, batchnorm = True, activate = True, **kwargs):\n",
        "        super(Conv2DBlock, self).__init__()\n",
        "\n",
        "        self.conv = Conv2D(filters = filters, **kwargs)\n",
        "        self.batchnorm = layers.BatchNormalization() if batchnorm else None\n",
        "        self.activate = layers.PReLU(shared_axes = [1, 2]) if activate else None\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        x = self.conv(inputs)\n",
        "        if self.batchnorm:\n",
        "            x = self.batchnorm(x)\n",
        "        if self.activate:\n",
        "            x = self.activate(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "vH_53MIDLwOc",
        "execution": {
          "iopub.status.busy": "2023-03-20T17:44:41.495033Z",
          "iopub.execute_input": "2023-03-20T17:44:41.495654Z",
          "iopub.status.idle": "2023-03-20T17:44:41.504321Z",
          "shell.execute_reply.started": "2023-03-20T17:44:41.495618Z",
          "shell.execute_reply": "2023-03-20T17:44:41.503338Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualDenseBlock(layers.Layer):\n",
        "    def __init__(self, filters = 64):\n",
        "        super(ResidualDenseBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = Conv2DBlock(filters = filters // 2)\n",
        "        self.conv2 = Conv2DBlock(filters = filters // 2)\n",
        "        self.conv3 = Conv2DBlock(filters = filters, activate = False)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x1 = self.conv1(inputs)\n",
        "        x2 = self.conv2(tf.concat([x1, inputs], 3))\n",
        "        outputs = self.conv3(tf.concat([x2, x1], 3))\n",
        "        \n",
        "        return outputs + inputs"
      ],
      "metadata": {
        "id": "O9A_biHn3gZ_",
        "execution": {
          "iopub.status.busy": "2023-03-20T17:44:41.505881Z",
          "iopub.execute_input": "2023-03-20T17:44:41.506300Z",
          "iopub.status.idle": "2023-03-20T17:44:41.516315Z",
          "shell.execute_reply.started": "2023-03-20T17:44:41.506266Z",
          "shell.execute_reply": "2023-03-20T17:44:41.515405Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RRDBlock(layers.Layer):\n",
        "    def __init__(self, filters, **kwargs):\n",
        "        super(RRDBlock, self).__init__(**kwargs)\n",
        "\n",
        "        self.rdb_1 = ResidualDenseBlock(filters)\n",
        "        self.rdb_2 = ResidualDenseBlock(filters)\n",
        "        self.rdb_3 = ResidualDenseBlock(filters)\n",
        "\n",
        "        self.rrdb_inputs_scales = tf.Variable(\n",
        "            tf.constant(value = 1.0, dtype = tf.float32, shape = [1, 1, 1, filters]),\n",
        "            name = f'{self.name}_rrdb_inputs_scales',\n",
        "            trainable = True\n",
        "        )\n",
        "        self.rrdb_outputs_scales = tf.Variable(\n",
        "            tf.constant(value = 0.5, dtype = tf.float32, shape = [1, 1, 1, filters]),\n",
        "            name = f'{self.name}_rrdb_outputs_scales',\n",
        "            trainable = True\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x1 = self.rdb_1(inputs)\n",
        "        x2 = self.rdb_2(x1)\n",
        "        outputs = self.rdb_3(x2)\n",
        "\n",
        "        return (self.rrdb_inputs_scales * inputs) + (self.rrdb_outputs_scales * outputs)"
      ],
      "metadata": {
        "id": "YOw44uaF6Duh",
        "execution": {
          "iopub.status.busy": "2023-03-20T17:44:41.517990Z",
          "iopub.execute_input": "2023-03-20T17:44:41.518371Z",
          "iopub.status.idle": "2023-03-20T17:44:41.529981Z",
          "shell.execute_reply.started": "2023-03-20T17:44:41.518321Z",
          "shell.execute_reply": "2023-03-20T17:44:41.529054Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PixelShuffleUpSampling(layers.Layer):\n",
        "    def __init__(self, filters, scale, **kwargs):\n",
        "        super(PixelShuffleUpSampling, self).__init__(**kwargs)\n",
        "\n",
        "        self.conv1 = Conv2DBlock(filters = filters, batchnorm = False, activate = False)\n",
        "        self.upsample = layers.Lambda(lambda x: tf.nn.depth_to_space(x, scale))\n",
        "        self.prelu = layers.PReLU(shared_axes = [1, 2])\n",
        "    \n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.upsample(x)\n",
        "        x = self.prelu(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "RDM9ag4F5TnO",
        "execution": {
          "iopub.status.busy": "2023-03-20T17:44:41.531724Z",
          "iopub.execute_input": "2023-03-20T17:44:41.532192Z",
          "iopub.status.idle": "2023-03-20T17:44:41.541278Z",
          "shell.execute_reply.started": "2023-03-20T17:44:41.532157Z",
          "shell.execute_reply": "2023-03-20T17:44:41.540318Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# __Building the models__"
      ],
      "metadata": {
        "id": "GsEz-kdSH_kc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Generator():\n",
        "    lr_image = layers.Input(shape = (None, None, 3))\n",
        "    \n",
        "    spatial_feats = layers.Lambda(lambda x: x / 255.0)(lr_image)\n",
        "    spatial_feats = Conv2DBlock(filters = GEN_FILTERS, kernel_size = 3, strides = 1, padding = 'same', batchnorm = False)(spatial_feats)\n",
        "    spatial_feats = Conv2DBlock(filters = GEN_FILTERS, kernel_size = 1, strides = 1, padding = 'valid', batchnorm = False)(spatial_feats)\n",
        "\n",
        "    rrdb1 = RRDBlock(GEN_FILTERS)(spatial_feats)\n",
        "    rrdb2 = RRDBlock(GEN_FILTERS)(rrdb1)\n",
        "    rrdb3 = RRDBlock(GEN_FILTERS)(rrdb2)\n",
        "    rrdb4 = RRDBlock(GEN_FILTERS)(rrdb3)\n",
        "\n",
        "    upsample1 = PixelShuffleUpSampling(GEN_FILTERS * 4, 2)(rrdb4)\n",
        "    upsample2 = PixelShuffleUpSampling(GEN_FILTERS * 4, 2)(upsample1)\n",
        "\n",
        "    x = Conv2DBlock(filters = GEN_FILTERS, batchnorm = False)(upsample2)\n",
        "    x = Conv2DBlock(filters = 3, kernel_size = 3, activate = False, batchnorm = False)(x)\n",
        "    x = layers.Activation('tanh')(x)\n",
        "\n",
        "    sr_image = layers.Lambda(lambda x: (x + 1) * 127.5)(x)\n",
        "\n",
        "    return Model(inputs = lr_image, outputs = sr_image, name = 'Generator')"
      ],
      "metadata": {
        "id": "xcbsCW_I7Zue",
        "execution": {
          "iopub.status.busy": "2023-03-20T17:44:41.546613Z",
          "iopub.execute_input": "2023-03-20T17:44:41.546890Z",
          "iopub.status.idle": "2023-03-20T17:44:41.556109Z",
          "shell.execute_reply.started": "2023-03-20T17:44:41.546858Z",
          "shell.execute_reply": "2023-03-20T17:44:41.555072Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Generator()\n",
        "generator.summary(100)"
      ],
      "metadata": {
        "id": "s_rOLqouAoxG",
        "execution": {
          "iopub.status.busy": "2023-03-20T17:44:41.558333Z",
          "iopub.execute_input": "2023-03-20T17:44:41.558731Z",
          "iopub.status.idle": "2023-03-20T17:44:42.577264Z",
          "shell.execute_reply.started": "2023-03-20T17:44:41.558693Z",
          "shell.execute_reply": "2023-03-20T17:44:42.576188Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_samples([lrs[:5], generator(lrs[:5])], titles = ['LR', 'SR'], size = (6, 6))"
      ],
      "metadata": {
        "id": "FVWQeusPRXYO",
        "execution": {
          "iopub.status.busy": "2023-03-20T17:44:42.578750Z",
          "iopub.execute_input": "2023-03-20T17:44:42.579649Z",
          "iopub.status.idle": "2023-03-20T17:44:49.537789Z",
          "shell.execute_reply.started": "2023-03-20T17:44:42.579609Z",
          "shell.execute_reply": "2023-03-20T17:44:49.536660Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Discriminator():\n",
        "    hr_image = layers.Input(shape = (HR_SIZE, HR_SIZE, 3))\n",
        "    x = layers.Lambda(lambda x: x / 127.5 - 1)(hr_image)\n",
        "\n",
        "    x = Conv2D(kernel_size = 3, filters = DISC_FILTERS // 2)(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = Conv2D(filters = DISC_FILTERS // 2, kernel_size = 3, strides = 2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = Conv2D(filters = DISC_FILTERS, kernel_size = 3)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = Conv2D(filters = DISC_FILTERS, kernel_size = 3, strides = 2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = Conv2D(filters = DISC_FILTERS * 2, kernel_size = 3, strides = 1)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = Conv2D(filters = DISC_FILTERS * 2, kernel_size = 3, strides = 2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = Conv2D(filters = DISC_FILTERS * 4, kernel_size = 3, strides = 1)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = Conv2D(filters = DISC_FILTERS * 4, kernel_size = 3, strides = 2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    \n",
        "    x = layers.Dense(1024)(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "    x = layers.Dense(1024)(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    logits = layers.Dense(1)(x)\n",
        "\n",
        "    return Model(inputs = hr_image, outputs = logits)"
      ],
      "metadata": {
        "id": "mGA8SjH1FWLO",
        "execution": {
          "iopub.status.busy": "2023-03-20T17:44:49.539348Z",
          "iopub.execute_input": "2023-03-20T17:44:49.540475Z",
          "iopub.status.idle": "2023-03-20T17:44:49.554738Z",
          "shell.execute_reply.started": "2023-03-20T17:44:49.540436Z",
          "shell.execute_reply": "2023-03-20T17:44:49.553619Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = Discriminator()\n",
        "discriminator.summary(100)"
      ],
      "metadata": {
        "id": "y9B2elceD8IC",
        "execution": {
          "iopub.status.busy": "2023-03-20T17:44:49.556247Z",
          "iopub.execute_input": "2023-03-20T17:44:49.556884Z",
          "iopub.status.idle": "2023-03-20T17:44:49.736202Z",
          "shell.execute_reply.started": "2023-03-20T17:44:49.556840Z",
          "shell.execute_reply": "2023-03-20T17:44:49.735158Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# __Defining training procedures__"
      ],
      "metadata": {
        "id": "zIpGRAi2IdAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PixelLossTraining:\n",
        "    def setup_pixel_loss(self, pixel_loss):\n",
        "        if pixel_loss == 'l1':\n",
        "            self.pixel_loss_type = losses.MeanAbsoluteError()\n",
        "        elif pixel_loss == 'l2':\n",
        "            self.pixel_loss_type = losses.MeanSquaredError()\n",
        "\n",
        "    @tf.function\n",
        "    def pixel_loss(self, srs, hrs):\n",
        "        return self.pixel_loss_type(hrs, srs)"
      ],
      "metadata": {
        "id": "HkV3_Vrw_Xu7",
        "execution": {
          "iopub.status.busy": "2023-03-20T17:44:49.737628Z",
          "iopub.execute_input": "2023-03-20T17:44:49.738023Z",
          "iopub.status.idle": "2023-03-20T17:44:49.745020Z",
          "shell.execute_reply.started": "2023-03-20T17:44:49.737984Z",
          "shell.execute_reply": "2023-03-20T17:44:49.743959Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VGGContentTraining:\n",
        "    def setup_content_loss(self, content_loss):\n",
        "        if content_loss == 'l1':\n",
        "            self.content_loss_type = losses.MeanAbsoluteError()\n",
        "        elif content_loss == 'l2':\n",
        "            self.content_loss_type = losses.MeanSquaredError()\n",
        "        \n",
        "        vgg = applications.VGG19(\n",
        "            input_shape = (224, 224, 3),\n",
        "            include_top = False,\n",
        "            weights = 'imagenet'\n",
        "        )\n",
        "        \n",
        "        vgg.layers[5].activation = None\n",
        "        vgg.layers[10].activation = None\n",
        "        vgg.layers[20].activation = None\n",
        "\n",
        "        self.feature_extrator = Model(\n",
        "            inputs = vgg.input,\n",
        "            outputs = [\n",
        "                vgg.layers[5].output,\n",
        "                vgg.layers[10].output,\n",
        "                vgg.layers[20].output\n",
        "            ]\n",
        "        )\n",
        "        for layer in self.feature_extrator.layers:\n",
        "            layer.trainable = False\n",
        "    \n",
        "    @tf.function\n",
        "    def content_loss(self, srs, hrs):\n",
        "        srs = applications.vgg19.preprocess_input(tf.image.resize(srs, (224, 224)))\n",
        "        hrs = applications.vgg19.preprocess_input(tf.image.resize(hrs, (224, 224)))\n",
        "        \n",
        "        srs_features = self.feature_extrator(srs)\n",
        "        hrs_features = self.feature_extrator(hrs)\n",
        "\n",
        "        loss = 0.0\n",
        "        for srs_feature, hrs_feature in zip(srs_features, hrs_features):\n",
        "            loss += self.content_loss_type(hrs_feature / 12.75, srs_feature / 12.75)\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "id": "Ubet71WN9CWX",
        "execution": {
          "iopub.status.busy": "2023-03-20T17:44:49.746767Z",
          "iopub.execute_input": "2023-03-20T17:44:49.747467Z",
          "iopub.status.idle": "2023-03-20T17:44:49.759618Z",
          "shell.execute_reply.started": "2023-03-20T17:44:49.747428Z",
          "shell.execute_reply": "2023-03-20T17:44:49.758635Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GramStyleTraining:\n",
        "    def setup_gram_style_loss(self, style_loss):\n",
        "        if style_loss == 'l1':\n",
        "            self.style_loss_type = losses.MeanAbsoluteError()\n",
        "        elif style_loss == 'l2':\n",
        "            self.style_loss_type = losses.MeanSquaredError()\n",
        "        \n",
        "        efficientnet = applications.EfficientNetB4(\n",
        "            input_shape = (224, 224, 3),\n",
        "            include_top = False,\n",
        "            weights = 'imagenet'\n",
        "        )\n",
        "        \n",
        "        self.style_features_extractor = Model(\n",
        "            inputs = efficientnet.input,\n",
        "            outputs = [\n",
        "                # efficientnet.layers[25].output,\n",
        "                # efficientnet.layers[84].output,\n",
        "                # efficientnet.layers[143].output,\n",
        "                efficientnet.layers[320].output,\n",
        "                # efficientnet.layers[467].output,\n",
        "            ]\n",
        "        )\n",
        "        for layer in self.style_features_extractor.layers:\n",
        "            layer.trainable = False\n",
        "\n",
        "    @tf.function\n",
        "    def gram_matrix(self, features):\n",
        "        features = tf.transpose(features, (0, 3, 1, 2)) # (-1, C, H, W)\n",
        "        features_a = tf.reshape(features, (tf.shape(features)[0], tf.shape(features)[1], -1)) # (-1, C, H * W)\n",
        "        features_b = tf.reshape(features, (tf.shape(features)[0], -1, tf.shape(features)[1])) # (-1, H * W, C)\n",
        "        \n",
        "        return tf.linalg.matmul(features_a, features_b) # (-1, C, C)\n",
        "\n",
        "    @tf.function\n",
        "    def gram_style_loss(self, srs, hrs):\n",
        "        srs = applications.efficientnet.preprocess_input(tf.image.resize(srs, (224, 224)))\n",
        "        hrs = applications.efficientnet.preprocess_input(tf.image.resize(hrs, (224, 224)))\n",
        "\n",
        "        srs_features = self.style_features_extractor(srs) # (2, -1, H, W, C)\n",
        "        hrs_features = self.style_features_extractor(hrs) # (2, -1, H, W, C)\n",
        "\n",
        "        # style_loss = 0.0\n",
        "        # for srs_feature, hrs_feature in zip(srs_features, hrs_features):\n",
        "        srs_gram = self.gram_matrix(srs_features)\n",
        "        hrs_gram = self.gram_matrix(hrs_features)\n",
        "\n",
        "        style_loss = self.style_loss_type(hrs_gram, srs_gram)\n",
        "\n",
        "        return style_loss"
      ],
      "metadata": {
        "id": "SKGqusURwdrP",
        "execution": {
          "iopub.status.busy": "2023-03-20T17:44:49.761217Z",
          "iopub.execute_input": "2023-03-20T17:44:49.761587Z",
          "iopub.status.idle": "2023-03-20T17:44:49.775682Z",
          "shell.execute_reply.started": "2023-03-20T17:44:49.761553Z",
          "shell.execute_reply": "2023-03-20T17:44:49.774480Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdversarialTraining:\n",
        "    def setup_adversarial_loss(self, adv_loss):\n",
        "        self.adv_loss_type = adv_loss\n",
        "        self.binary_cross_entropy = losses.BinaryCrossentropy(from_logits = True)\n",
        "\n",
        "    @tf.function\n",
        "    def gen_adv_loss(self, fake_logits, real_logits = None):\n",
        "        if self.adv_loss_type == 'gan':\n",
        "            loss = self.binary_cross_entropy(tf.ones_like(fake_logits), fake_logits)\n",
        "        \n",
        "        elif self.adv_loss_type == 'ragan':\n",
        "            real_loss = self.binary_cross_entropy(tf.ones_like(fake_logits), fake_logits - tf.reduce_mean(real_logits))\n",
        "            fake_loss = self.binary_cross_entropy(tf.zeros_like(real_logits), real_logits - tf.reduce_mean(fake_logits))\n",
        "            loss = real_loss + fake_loss\n",
        "        \n",
        "        return loss\n",
        "        \n",
        "    @tf.function\n",
        "    def disc_adv_loss(self, fake_logits, real_logits):\n",
        "        if self.adv_loss_type == 'gan':\n",
        "            real_loss = self.binary_cross_entropy(tf.ones_like(real_logits), real_logits)\n",
        "            fake_loss = self.binary_cross_entropy(tf.zeros_like(fake_logits), fake_logits)\n",
        "        \n",
        "        elif self.adv_loss_type == 'ragan':\n",
        "            real_loss = self.binary_cross_entropy(tf.ones_like(real_logits), real_logits - tf.reduce_mean(fake_logits))\n",
        "            fake_loss = self.binary_cross_entropy(tf.zeros_like(fake_logits), fake_logits - tf.reduce_mean(real_logits))\n",
        "        \n",
        "        return real_loss + fake_loss"
      ],
      "metadata": {
        "id": "o0ULUszS-Mkv",
        "execution": {
          "iopub.status.busy": "2023-03-20T17:44:49.777417Z",
          "iopub.execute_input": "2023-03-20T17:44:49.777791Z",
          "iopub.status.idle": "2023-03-20T17:44:49.789777Z",
          "shell.execute_reply.started": "2023-03-20T17:44:49.777752Z",
          "shell.execute_reply": "2023-03-20T17:44:49.788803Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# __Defining SRGAN Model__"
      ],
      "metadata": {
        "id": "T7HAfaz3PQzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SRGAN(\n",
        "        Model,\n",
        "        PixelLossTraining,\n",
        "        GramStyleTraining,\n",
        "        VGGContentTraining,\n",
        "        AdversarialTraining\n",
        "    ):\n",
        "    def __init__(\n",
        "        self,\n",
        "        generator,\n",
        "        discriminator,\n",
        "    ):\n",
        "        super(SRGAN, self).__init__(self, dynamic = True)\n",
        "\n",
        "        self.generator = generator\n",
        "        self.discriminator = discriminator\n",
        "    \n",
        "    def compile(\n",
        "        self,\n",
        "\n",
        "        generator_optimizer, \n",
        "        discriminator_optimizer,\n",
        "\n",
        "        perceptual_finetune,\n",
        "\n",
        "        pixel_loss,\n",
        "        style_loss,\n",
        "        content_loss,\n",
        "        adv_loss,\n",
        "\n",
        "        loss_weights,\n",
        "    ):\n",
        "        super(SRGAN, self).compile()\n",
        "\n",
        "        self.generator.optimizer = generator_optimizer\n",
        "        self.discriminator.optimizer = discriminator_optimizer\n",
        "\n",
        "        self.perceptual_finetune = perceptual_finetune\n",
        "\n",
        "        self.setup_pixel_loss(pixel_loss)\n",
        "        # self.setup_gram_style_loss(style_loss)\n",
        "        self.setup_content_loss(content_loss)\n",
        "        self.setup_adversarial_loss(adv_loss)\n",
        "\n",
        "        if self.perceptual_finetune:\n",
        "            self.loss_weights = loss_weights\n",
        "\n",
        "    def train_step(self, batch):\n",
        "        self.lrs = batch[0]\n",
        "        self.hrs = batch[1]\n",
        "\n",
        "        if self.perceptual_finetune:\n",
        "            # [=================== Training Discriminator ===================]\n",
        "\n",
        "            with tf.GradientTape() as disc_tape, tf.GradientTape() as gen_tape:\n",
        "                self.srs = self.generator(self.lrs, training = True)\n",
        "\n",
        "                real_logits = self.discriminator(self.hrs, training = True)\n",
        "                fake_logits = self.discriminator(self.srs, training = True)\n",
        "\n",
        "                content_loss = self.loss_weights['content_loss'] * self.content_loss(self.srs, self.hrs)\n",
        "                gen_adv_loss = self.loss_weights['adv_loss'] * self.gen_adv_loss(fake_logits, real_logits)\n",
        "                perceptual_loss = content_loss + gen_adv_loss\n",
        "                \n",
        "                # style_loss = self.loss_weights['style_loss'] * self.gram_style_loss(self.srs, self.hrs)\n",
        "\n",
        "                gen_loss = perceptual_loss\n",
        "\n",
        "                disc_adv_loss = self.disc_adv_loss(fake_logits, real_logits)\n",
        "            \n",
        "            discriminator_gradients = disc_tape.gradient(disc_adv_loss, self.discriminator.trainable_variables)\n",
        "            generator_gradients = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
        "            \n",
        "            self.discriminator.optimizer.apply_gradients(zip(discriminator_gradients, self.discriminator.trainable_variables))\n",
        "            self.generator.optimizer.apply_gradients(zip(generator_gradients, self.generator.trainable_variables))\n",
        "\n",
        "            return {\n",
        "                'Perceptual Loss': perceptual_loss,\n",
        "                # 'Style Loss': style_loss,\n",
        "                'Generator Adv Loss': gen_adv_loss,\n",
        "                'Discriminator Adv Loss': disc_adv_loss,\n",
        "            }\n",
        "        \n",
        "        else:\n",
        "            with tf.GradientTape() as gen_tape:\n",
        "                self.srs = self.generator(self.lrs, training = True)\n",
        "\n",
        "                pixel_loss = self.pixel_loss(self.srs, self.hrs)\n",
        "\n",
        "            generator_gradients = gen_tape.gradient(pixel_loss, self.generator.trainable_variables)\n",
        "            self.generator.optimizer.apply_gradients(zip(generator_gradients, self.generator.trainable_variables))\n",
        "\n",
        "            return {\n",
        "                'Pixel Loss': pixel_loss,\n",
        "            }"
      ],
      "metadata": {
        "id": "PhzhBBYiIb_B",
        "execution": {
          "iopub.status.busy": "2023-03-20T17:44:49.791592Z",
          "iopub.execute_input": "2023-03-20T17:44:49.791982Z",
          "iopub.status.idle": "2023-03-20T17:44:49.807904Z",
          "shell.execute_reply.started": "2023-03-20T17:44:49.791948Z",
          "shell.execute_reply": "2023-03-20T17:44:49.806750Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# __Checkpoint Callback__"
      ],
      "metadata": {
        "id": "JOb04JhmPUT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CheckpointCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, checkpoint_dir, resume = False, epoch_step = 1):\n",
        "        super(CheckpointCallback, self).__init__()\n",
        "        \n",
        "        self.checkpoint_dir = checkpoint_dir\n",
        "        self.resume = resume\n",
        "        self.epoch_step = epoch_step\n",
        "    \n",
        "    def setup_checkpoint(self, *args, **kwargs):\n",
        "        self.checkpoint = tf.train.Checkpoint(\n",
        "            generator = self.model.generator,\n",
        "            discriminator = self.model.discriminator,\n",
        "            generator_optimizer = self.model.generator.optimizer,\n",
        "            discriminator_optimizer = self.model.discriminator.optimizer\n",
        "        )\n",
        "        self.manager = tf.train.CheckpointManager(\n",
        "            self.checkpoint,\n",
        "            directory = self.checkpoint_dir,\n",
        "            checkpoint_name = 'SRGAN',\n",
        "            max_to_keep = 1\n",
        "        )\n",
        "\n",
        "        if self.resume:\n",
        "            self.load_checkpoint()\n",
        "        else:\n",
        "            print('Starting training from scratch...\\n')\n",
        "        \n",
        "    def on_batch_end(self, batch, *args, **kwargs): \n",
        "        if (batch + 1) % int(self.epoch_step * len(train_data)) == 0:\n",
        "            print(f\"\\n\\nCheckpoint saved to {self.manager.save()}\\n\")\n",
        "    \n",
        "    def load_checkpoint(self):\n",
        "        if self.manager.latest_checkpoint:\n",
        "            self.checkpoint.restore(self.manager.latest_checkpoint)\n",
        "            print(f\"Checkpoint restored from '{self.manager.latest_checkpoint}'\\n\")\n",
        "        else:\n",
        "            print(\"No checkpoints found, initializing from scratch...\\n\")\n",
        "    \n",
        "    def set_lr(self, lr, beta_1 = 0.9):\n",
        "        print(f'Continuing with learning rate: {lr}')\n",
        "        self.model.generator.optimizer.beta_1 = beta_1\n",
        "        self.model.generator.optimizer.learning_rate = lr\n",
        "        self.model.discriminator.optimizer.beta_1 = beta_1\n",
        "        self.model.discriminator.optimizer.learning_rate = lr"
      ],
      "metadata": {
        "id": "e_cVvL2ZipNj",
        "execution": {
          "iopub.status.busy": "2023-03-20T17:44:49.809935Z",
          "iopub.execute_input": "2023-03-20T17:44:49.810555Z",
          "iopub.status.idle": "2023-03-20T17:44:49.822370Z",
          "shell.execute_reply.started": "2023-03-20T17:44:49.810518Z",
          "shell.execute_reply": "2023-03-20T17:44:49.821664Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# __Optimization Progress Callback__"
      ],
      "metadata": {
        "id": "kWcT0FVOPXWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ProgressCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, logs_step, generator_step):\n",
        "        super(ProgressCallback, self).__init__()\n",
        "\n",
        "        self.logs_step = logs_step\n",
        "        self.generator_step = generator_step\n",
        "\n",
        "    def on_batch_end(self, batch, logs, **kwargs):\n",
        "        if (batch + 1) % int(self.generator_step * len(train_data)) == 0:\n",
        "            if self.model.perceptual_finetune:\n",
        "                visualize_samples(\n",
        "                    images_lists = (self.model.lrs[:3], self.model.srs[:3], self.model.hrs[:3]),\n",
        "                    titles = ('Low Resolution', 'Predicted Enhanced', 'High Resolution'),\n",
        "                    size = (11, 11)\n",
        "                )\n",
        "            else:\n",
        "                visualize_samples(\n",
        "                    images_lists = (self.model.lrs[:3], self.model.srs[:3]),\n",
        "                    titles = ('Low Resolution', 'Predicted Enhanced'),\n",
        "                    size = (7, 7)\n",
        "                )"
      ],
      "metadata": {
        "id": "RhuCuFOQ0chZ",
        "execution": {
          "iopub.status.busy": "2023-03-20T17:44:49.823645Z",
          "iopub.execute_input": "2023-03-20T17:44:49.824642Z",
          "iopub.status.idle": "2023-03-20T17:44:49.835018Z",
          "shell.execute_reply.started": "2023-03-20T17:44:49.824606Z",
          "shell.execute_reply": "2023-03-20T17:44:49.834411Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# __Optimization Config Values__"
      ],
      "metadata": {
        "id": "hNHO0MipPaPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 100\n",
        "LR = 0.00002\n",
        "BETA_1 = 0.8\n",
        "BETA_2 = 0.999\n",
        "\n",
        "PERCEPTUAL_FINETUNE = True\n",
        "\n",
        "PIXEL_LOSS = 'l1'\n",
        "STYLE_LOSS = 'l1'\n",
        "CONTENT_LOSS = 'l1'\n",
        "ADV_LOSS = 'ragan'\n",
        "\n",
        "LOSS_WEIGHTS = {'content_loss': 1.0, 'adv_loss': 0.09, 'style_loss': 1.0}\n",
        "\n",
        "CHECKPOINT_DIR = os.path.join('drive', 'MyDrive', 'Model-Checkpoints', 'Super Resolution')"
      ],
      "metadata": {
        "id": "oNI3-2p_ICmx",
        "execution": {
          "iopub.status.busy": "2023-03-20T17:44:49.836254Z",
          "iopub.execute_input": "2023-03-20T17:44:49.837320Z",
          "iopub.status.idle": "2023-03-20T17:44:49.847038Z",
          "shell.execute_reply.started": "2023-03-20T17:44:49.837282Z",
          "shell.execute_reply": "2023-03-20T17:44:49.846421Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# __Initializing Models__"
      ],
      "metadata": {
        "id": "hMmGGsTRPdxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator_optimizer = optimizers.Adam(\n",
        "    learning_rate = LR,\n",
        "    beta_1 = BETA_1,\n",
        "    beta_2 = BETA_2\n",
        ")\n",
        "discriminator_optimizer = optimizers.Adam(\n",
        "    learning_rate = LR,\n",
        "    beta_1 = BETA_1,\n",
        "    beta_2 = BETA_2\n",
        ")\n",
        "\n",
        "srgan = SRGAN(generator, discriminator)\n",
        "srgan.compile(\n",
        "    generator_optimizer = generator_optimizer,\n",
        "    discriminator_optimizer = discriminator_optimizer,\n",
        "    \n",
        "    perceptual_finetune = PERCEPTUAL_FINETUNE,\n",
        "    pixel_loss = PIXEL_LOSS,\n",
        "    style_loss = STYLE_LOSS,\n",
        "    content_loss = CONTENT_LOSS,\n",
        "    adv_loss = ADV_LOSS,\n",
        "\n",
        "    loss_weights = LOSS_WEIGHTS\n",
        ")"
      ],
      "metadata": {
        "id": "ZlHf8h0XGX4y",
        "execution": {
          "iopub.status.busy": "2023-03-20T17:44:49.848220Z",
          "iopub.execute_input": "2023-03-20T17:44:49.849263Z",
          "iopub.status.idle": "2023-03-20T17:44:53.775581Z",
          "shell.execute_reply.started": "2023-03-20T17:44:49.849228Z",
          "shell.execute_reply": "2023-03-20T17:44:53.774569Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# __Setting up checkpoint callback__"
      ],
      "metadata": {
        "id": "XaHJotvHVgcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt_callback = CheckpointCallback(\n",
        "    checkpoint_dir = CHECKPOINT_DIR,\n",
        "    resume = True,\n",
        "    epoch_step = 4\n",
        ")\n",
        "ckpt_callback.set_model(srgan)\n",
        "ckpt_callback.setup_checkpoint(srgan)\n",
        "ckpt_callback.set_lr(0.0002, BETA_1)"
      ],
      "metadata": {
        "id": "GxKeX6FHRA_B",
        "execution": {
          "iopub.status.busy": "2023-03-20T17:44:53.777235Z",
          "iopub.execute_input": "2023-03-20T17:44:53.777610Z",
          "iopub.status.idle": "2023-03-20T17:44:53.784591Z",
          "shell.execute_reply.started": "2023-03-20T17:44:53.777573Z",
          "shell.execute_reply": "2023-03-20T17:44:53.783617Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# __Training the Model__"
      ],
      "metadata": {
        "id": "D8GexvF7PkGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "srgan.fit(\n",
        "    train_data.repeat(EPOCHS // 10),\n",
        "    epochs = 5,\n",
        "    callbacks = [\n",
        "        ckpt_callback,\n",
        "        ProgressCallback(\n",
        "            logs_step = 0.2,\n",
        "            generator_step = 2\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "8vTzfjDCvugf",
        "execution": {
          "iopub.status.busy": "2023-03-20T17:44:53.785871Z",
          "iopub.execute_input": "2023-03-20T17:44:53.786841Z",
          "iopub.status.idle": "2023-03-20T18:50:14.512615Z",
          "shell.execute_reply.started": "2023-03-20T17:44:53.786803Z",
          "shell.execute_reply": "2023-03-20T18:50:14.510588Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# __Testing the model__"
      ],
      "metadata": {
        "id": "hYW1IsO2IfQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def enhance_image(lr_image = None, path = None, output_path = None, visualize = True, size = (20, 16)):\n",
        "    assert any([lr_image is not None, path])\n",
        "    if path:\n",
        "        lr_image = tf.image.decode_jpeg(tf.io.read_file(f\"{path}\"), channels = 3)\n",
        "\n",
        "    sr_image = srgan.generator(tf.expand_dims(lr_image, 0), training = False)[0]\n",
        "    sr_image = tf.clip_by_value(sr_image, 0, 255)\n",
        "    sr_image = tf.round(sr_image)\n",
        "    sr_image = tf.cast(sr_image, tf.uint8)\n",
        "\n",
        "    if visualize:\n",
        "        visualize_samples(images_lists = [[lr_image], [sr_image]], titles = ['LR Image', 'SR_Image'], size = size)\n",
        "\n",
        "    if output_path:\n",
        "        tf.io.write_file(output_path, tf.image.encode_jpeg(sr_image))"
      ],
      "metadata": {
        "id": "p8aRahA0cgWl",
        "execution": {
          "iopub.status.busy": "2023-03-20T18:50:49.378804Z",
          "iopub.execute_input": "2023-03-20T18:50:49.379195Z",
          "iopub.status.idle": "2023-03-20T18:50:49.387277Z",
          "shell.execute_reply.started": "2023-03-20T18:50:49.379164Z",
          "shell.execute_reply": "2023-03-20T18:50:49.386219Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, (lr, _) in enumerate(tfds.load(f'div2k/bicubic_x{SCALE}', split = 'validation', shuffle_files = True).shuffle(100).take(20).map(random_compression, num_parallel_calls = tf.data.AUTOTUNE)):\n",
        "    lr_x = tf.random.uniform(maxval = int(lr.shape[1] // 2), shape = (), dtype = tf.int32)\n",
        "    lr_y = tf.random.uniform(maxval = int(lr.shape[0] // 2), shape = (), dtype = tf.int32)\n",
        "    lr = lr[lr_x: lr_x + 100, lr_y: lr_y + 100, :]\n",
        "    sr = enhance_image(lr_image = lr)"
      ],
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YwnVTL9ewcLI",
        "execution": {
          "iopub.status.busy": "2023-03-20T18:50:52.121552Z",
          "iopub.execute_input": "2023-03-20T18:50:52.121923Z",
          "iopub.status.idle": "2023-03-20T18:51:12.981378Z",
          "shell.execute_reply.started": "2023-03-20T18:50:52.121892Z",
          "shell.execute_reply": "2023-03-20T18:51:12.980284Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p-J3cAa5UujR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}